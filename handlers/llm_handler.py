import logging
from collections import defaultdict
from typing import Dict, List, Optional

from openai import AsyncOpenAI

from config import Config

logger = logging.getLogger(__name__)

# â”€â”€ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ñ‹ â”€â”€

SYSTEM_PROMPT_CHAT = (
    "Ğ¢Ñ‹ â€” Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¼Ğ»Ğ¸Ğ´Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑÑ‚Ñ€ĞµĞ¼Ğ¸Ñ‚ÑÑ ÑÑ‚Ğ°Ñ‚ÑŒ CTO. "
    "ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ‚Ğ¾Ğ¼ Ğ¶Ğµ ÑĞ·Ñ‹ĞºĞµ, Ğ½Ğ° ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ·Ğ°Ğ´Ğ°Ğ½ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ. "
    "ĞšĞ¾Ğ³Ğ´Ğ° ÑƒĞ¼ĞµÑÑ‚Ğ½Ğ¾ â€” ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ğ¹ ĞºĞ°Ñ€ÑŒĞµÑ€Ğ½Ñ‹Ğµ Ñ†ĞµĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ. "
    "Ğ‘ÑƒĞ´ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼, Ğ´Ğ°Ğ²Ğ°Ğ¹ actionable ÑĞ¾Ğ²ĞµÑ‚Ñ‹."
)

SYSTEM_PROMPT_ARTICLE = """Ğ¢Ñ‹ â€” Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¼Ğ»Ğ¸Ğ´Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑÑ‚Ñ€ĞµĞ¼Ğ¸Ñ‚ÑÑ ÑÑ‚Ğ°Ñ‚ÑŒ CTO.

ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ¸ Ğ´Ğ°Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ **Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ**:

1. ğŸ“Œ **Ğ¡Ğ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸** â€” ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¸Ğ·Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ (3-5 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹)
2. ğŸ’¡ **ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¸Ğ´ĞµĞ¸** â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ğ¼Ñ‹ÑĞ»ĞµĞ¹ (3-7 Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ²)
3. ğŸ¯ **ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¿ÑƒÑ‚Ğ¸ TL â†’ CTO** â€” Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¾Ñ‚ 1 Ğ´Ğ¾ 10 Ñ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
4. ğŸ“‚ **ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ** â€” Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ / Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° / Ğ¼ĞµĞ½ĞµĞ´Ğ¶Ğ¼ĞµĞ½Ñ‚ / Ğ»Ğ¸Ğ´ĞµÑ€ÑÑ‚Ğ²Ğ¾ / ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ / Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚ / ĞºÑƒĞ»ÑŒÑ‚ÑƒÑ€Ğ° / Ğ´Ñ€ÑƒĞ³Ğ¾Ğµ
5. âœ… **Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ** â€” ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ»Ğ¸ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ, ĞºĞ¾Ğ¼Ñƒ Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ
6. ğŸ”‘ **Actionable insights** â€” Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ

Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ½Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ â€” Ğ¿ĞµÑ€ĞµĞ²ĞµĞ´Ğ¸ Ğ²ÑĞµ Ğ¿ÑƒĞ½ĞºÑ‚Ñ‹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¸Ğ¹.
Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ°Ñ‚ÑŒÑ ÑĞ»Ğ°Ğ±Ğ°Ñ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ°Ñ â€” ÑĞºĞ°Ğ¶Ğ¸ Ğ¾Ğ± ÑÑ‚Ğ¾Ğ¼ Ğ¿Ñ€ÑĞ¼Ğ¾."""

SYSTEM_PROMPT_BOOK = """Ğ¢Ñ‹ â€” Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ñ‚Ğ¸Ğ¼Ğ»Ğ¸Ğ´Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑÑ‚Ñ€ĞµĞ¼Ğ¸Ñ‚ÑÑ ÑÑ‚Ğ°Ñ‚ÑŒ CTO.

ĞÑ†ĞµĞ½Ğ¸ ĞºĞ½Ğ¸Ğ³Ñƒ Ğ¸ Ğ´Ğ°Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ **Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ**:

1. ğŸ“– **Ğ Ñ‡Ñ‘Ğ¼ ĞºĞ½Ğ¸Ğ³Ğ°** â€” ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ (2-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
2. ğŸ¯ **ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¿ÑƒÑ‚Ğ¸ TL â†’ CTO** â€” Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¾Ñ‚ 1 Ğ´Ğ¾ 10 Ñ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
3. ğŸ“‚ **ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ** â€” Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶Ğ¼ĞµĞ½Ñ‚ / Ğ»Ğ¸Ğ´ĞµÑ€ÑÑ‚Ğ²Ğ¾ / Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° / ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ / soft skills / Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ / Ğ´Ñ€ÑƒĞ³Ğ¾Ğµ
4. ğŸ’¡ **Ğ§ĞµĞ¼Ñƒ Ğ½Ğ°ÑƒÑ‡Ğ¸Ñ‚** â€” Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¸ Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ (ÑĞ¿Ğ¸ÑĞ¾Ğº)
5. â± **ĞšĞ¾Ğ³Ğ´Ğ° Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ** â€” Ğ½Ğ° ĞºĞ°ĞºĞ¾Ğ¼ ÑÑ‚Ğ°Ğ¿Ğµ ĞºĞ°Ñ€ÑŒĞµÑ€Ñ‹ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ° (TL / Senior TL / Engineering Manager / VP Eng / CTO)
6. âš¡ **ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¸Ğ´ĞµĞ¸** â€” 3-5 ÑĞ°Ğ¼Ñ‹Ñ… Ğ²Ğ°Ğ¶Ğ½Ñ‹Ñ… Ğ¼Ñ‹ÑĞ»ĞµĞ¹ Ğ¸Ğ· ĞºĞ½Ğ¸Ğ³Ğ¸
7. ğŸ“š **ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ñ‹** â€” 2-3 Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğµ ĞºĞ½Ğ¸Ğ³Ğ¸ (Ğ»ÑƒÑ‡ÑˆĞµ/Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‰Ğ¸Ğµ)
8. ğŸ† **Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚** â€” ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ»Ğ¸ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ, Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ (must read / ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ / Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ / Ğ½Ğµ ÑÑ‚Ğ¾Ğ¸Ñ‚)

Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ·Ğ½Ğ°ĞµÑˆÑŒ ĞºĞ½Ğ¸Ğ³Ñƒ â€” Ñ‡ĞµÑÑ‚Ğ½Ğ¾ ÑĞºĞ°Ğ¶Ğ¸ Ğ¸ Ğ´Ğ°Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ/Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ°.
Ğ•ÑĞ»Ğ¸ ĞºĞ½Ğ¸Ğ³Ğ° ÑƒÑÑ‚Ğ°Ñ€ĞµĞ»Ğ° â€” Ğ¾Ñ‚Ğ¼ĞµÑ‚ÑŒ ÑÑ‚Ğ¾ Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ·Ğ°Ğ¼ĞµĞ½Ñƒ."""


class LLMHandler:
    def __init__(self):
        self.conversations: Dict[int, List[Dict[str, str]]] = defaultdict(list)
        self.config = Config()
        self.client: Optional[AsyncOpenAI] = None

        if not self.config.OPENROUTER_API_KEY:
            logger.error("OPENROUTER_API_KEY Ğ½Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½!")
        else:
            try:
                self.client = AsyncOpenAI(
                    base_url=self.config.OPENROUTER_BASE_URL,
                    api_key=self.config.OPENROUTER_API_KEY,
                    timeout=120.0,
                    max_retries=2,
                    default_headers=self._build_extra_headers(),
                )
                logger.info("OpenRouter OK, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: %s", self.config.LLM_MODEL)
            except Exception as e:
                logger.error("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ OpenRouter: %s", e)

    def _build_extra_headers(self) -> Dict[str, str]:
        headers: Dict[str, str] = {}
        if self.config.OPENROUTER_SITE_URL:
            headers["HTTP-Referer"] = self.config.OPENROUTER_SITE_URL
        if self.config.OPENROUTER_APP_NAME:
            headers["X-Title"] = self.config.OPENROUTER_APP_NAME
        return headers

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ĞĞ¸Ğ·ĞºĞ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² API
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _call_api(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> str:
        if not self.client:
            return (
                "âŒ OpenRouter ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ½Ğµ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ OPENROUTER_API_KEY."
            )

        try:
            response = await self.client.chat.completions.create(
                model=self.config.LLM_MODEL,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
            )
            content = response.choices[0].message.content
            if not content:
                return "âš ï¸ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²ĞµÑ€Ğ½ÑƒĞ»Ğ° Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚."

            if response.usage:
                logger.info(
                    "Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: prompt=%d, completion=%d, total=%d",
                    response.usage.prompt_tokens,
                    response.usage.completion_tokens,
                    response.usage.total_tokens,
                )
            return content

        except Exception as e:
            return self._handle_api_error(e)

    def _handle_api_error(self, e: Exception) -> str:
        err = str(e)
        if "401" in err or "Unauthorized" in err:
            return "âŒ ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ API ĞºĞ»ÑÑ‡ OpenRouter."
        if "402" in err or "Payment Required" in err:
            return "âŒ ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ÑÑ€ĞµĞ´ÑÑ‚Ğ² Ğ½Ğ° OpenRouter."
        if "429" in err or "rate limit" in err.lower():
            return "â³ Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ². ĞŸĞ¾Ğ´Ğ¾Ğ¶Ğ´Ğ¸Ñ‚Ğµ."
        if "model" in err.lower() and "not found" in err.lower():
            return f"âŒ ĞœĞ¾Ğ´ĞµĞ»ÑŒ `{self.config.LLM_MODEL}` Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°."
        logger.error("OpenRouter error: %s", e, exc_info=True)
        return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° API: {e}"

    def _prepare_messages(self, user_id: int) -> List[Dict[str, str]]:
        messages = [{"role": "system", "content": SYSTEM_PROMPT_CHAT}]
        history = self.conversations[user_id][-(self.config.MAX_HISTORY * 2) :]
        messages.extend(history)
        return messages

    async def get_response(self, user_id: int, message: str) -> str:
        self.conversations[user_id].append({"role": "user", "content": message})

        max_items = self.config.MAX_HISTORY * 2
        if len(self.conversations[user_id]) > max_items:
            self.conversations[user_id] = self.conversations[user_id][-max_items:]

        try:
            messages = self._prepare_messages(user_id)
            response = await self._call_api(messages)
            self.conversations[user_id].append(
                {"role": "assistant", "content": response}
            )
            return response
        except Exception as e:
            logger.error("get_response error: %s", e, exc_info=True)
            return f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"

    async def summarize_article(
        self, text: str, title: str, language: str, url: str
    ) -> str:
        # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²
        max_chars = self.config.ARTICLE_MAX_CHARS
        truncated = text[:max_chars]
        if len(text) > max_chars:
            truncated += "\n\n[...Ñ‚ĞµĞºÑÑ‚ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½...]"

        user_msg = (
            f"**ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ:** {title}\n"
            f"**URL:** {url}\n"
            f"**Ğ¯Ğ·Ñ‹Ğº Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğ°:** {language}\n"
            f"**Ğ¡Ğ»Ğ¾Ğ²:** ~{len(text.split())}\n\n"
            f"**Ğ¢ĞµĞºÑÑ‚ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸:**\n{truncated}"
        )

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT_ARTICLE},
            {"role": "user", "content": user_msg},
        ]
        return await self._call_api(messages, temperature=0.3)

    async def evaluate_book(self, book_info: str) -> str:
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT_BOOK},
            {"role": "user", "content": f"ĞÑ†ĞµĞ½Ğ¸ ĞºĞ½Ğ¸Ğ³Ñƒ: {book_info}"},
        ]
        return await self._call_api(messages, temperature=0.3)

    def clear_history(self, user_id: int) -> bool:
        if user_id in self.conversations and self.conversations[user_id]:
            self.conversations[user_id] = []
            return True
        return False

    def get_history_length(self, user_id: int) -> int:
        return len(self.conversations.get(user_id, []))
